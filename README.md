# ğŸ©º Predicting Bodyâ€‘Weight & Obesity Risk with R

![R](https://img.shields.io/badge/R-Programming-blue?logo=r)
![Status](https://img.shields.io/badge/Project-Complete-brightgreen)
![Models](https://img.shields.io/badge/Models-Linear%20Reg%20%7C%20Tree%20%7C%20Random%20Forest-orange)
![Dataset](https://img.shields.io/badge/Data-UCI--Obesity%20%28n=2111%29-lightgrey)

> **Goal**â€ƒIdentify the demographic & behavioural drivers of bodyâ€‘weight and pinpoint the model that best predicts weight (kg).

---

## ğŸ“‘ Contents
1. [Background](#background)  
2. [Dataset](#dataset)  
3. [Exploratory Data Analysis](#exploratory-data-analysis)  
4. [Modelling Workflow](#modelling-workflow)  
5. [Results](#results)  
6. [Interpretation](#interpretation)  
7. [Reproduction](#reproduction)  


---

## Background
Obesity is a growing global epidemic.  Using the **UCI â€œEstimation of Obesity Levelsâ€** repository, this study treats **Weight** as the response variable and benchmarks three algorithmsâ€”stepwise **linear regression**, **regression tree (CART)**, and **random forest**â€”to evaluate predictive power and business realism. :contentReference[oaicite:0]{index=0}

---

## Dataset
* **Rows**Â â€¯2â€¯111  
* **Predictors**Â 17 demographic & lifestyle features  
* **Target**Â WeightÂ (kg)  
* All variables are numeric or factorâ€‘encoded.  See full variable glossary in the report. :contentReference[oaicite:1]{index=1}

---

## Exploratory Data Analysis
* **Demographics** skew younger; max ageâ€¯=â€¯61, minâ€¯=â€¯14.  
* **Weight distribution** is bimodal (â‰ˆâ€¯60â€“70â€¯kg & 90â€“100â€¯kg peaks).  
* **Height vsâ€¯Weight** shows positive correlation with notable heteroskedasticity. :contentReference[oaicite:2]{index=2}  
* **Obesity class (`NObeyesdad`)** strongly stratifies weight ranges. :contentReference[oaicite:3]{index=3}  

Visuals (histograms, scatter, density) are saved inâ€¯`/fig/` for quick reference.

---

## Modelling Workflow
| Step | Technique | Key Details & Diagnostics |
|------|-----------|---------------------------|
| **1** | LinearÂ RegressionÂ +Â Stepwise | 90â€¯/â€¯10 trainâ€‘test;Â *RÂ²Â â‰ˆâ€¯0.963*; insignificant vars (e.g., **SMOKE**, **SCC**) dropped.Â TestÂ MAEâ€¯â‰ˆâ€¯3.7â€¯kg. :contentReference[oaicite:4]{index=4} |
| **2** | Regression Tree (CART) | Splits driven mainly by **NObeyesdad** and **Height**; postâ€‘prune CPâ€¯â‰ˆâ€¯0.0015; trainingÂ MSEâ€¯â‰ˆâ€¯7.07, testÂ MSEâ€¯â‰ˆâ€¯20.75. :contentReference[oaicite:5]{index=5} |
| **3** | Random Forest | 100 trees, *mtryâ€¯=â€¯5*; trainingÂ MSEâ€¯â‰ˆâ€¯12.35, testÂ MSEâ€¯â‰ˆâ€¯59.19; top importance: **NObeyesdad**, **Height**, family history. :contentReference[oaicite:6]{index=6} |

---

## Results
| Model                | TrainÂ MSE | TestÂ MSE | Overfit? |
|----------------------|-----------|----------|----------|
| Linearâ€¯Regression    | **25.95** | **23.85** | Low |
| Regressionâ€¯Tree      | 7.07 | 20.75 | Moderate |
| Randomâ€¯Forest        | 12.35 | 59.19 | High |

*Linear regression* offers the lowest generalisation error despite its simpler form.  Full score table reproduced. :contentReference[oaicite:7]{index=7}

---

## Interpretation
* **`NObeyesdad`** (obesity category) and **Height** consistently rank as dominant predictors, aligning with physiological expectations. :contentReference[oaicite:8]{index=8}  
* Tree structure exposes nonâ€‘linear thresholdsâ€”for instance, heights â‰¥â€¯1.649â€¯m raise expected weight by ~16â€¯kg within *Overweight Iâ€“II* strata. :contentReference[oaicite:9]{index=9}  
* Randomâ€‘forest overfit indicates excessive model variance; tuning *ntree* and *mtry* or additional crossâ€‘validation could close the gap.

Overall, **stepwise linear regression balances accuracy and interpretability**, making it the preferred choice for practical deployment. :contentReference[oaicite:10]{index=10}

---

## Reproduction

```bash
# clone repo
git clone https://github.com/yourâ€‘username/obesityâ€‘weightâ€‘prediction.git
cd obesityâ€‘weightâ€‘prediction

# open R and install dependencies
install.packages(c(
  "tidyverse","rpart","rpart.plot",
  "randomForest","leaps"
))

# run analysis
source("analysis.R")
